From cfb328633f8d4a0424e3e72d98c1ccc73c2358c5 Mon Sep 17 00:00:00 2001
From: Oleksandr Tyshchenko <oleksandr_tyshchenko@epam.com>
Date: Sat, 3 Jun 2023 18:37:37 +0300
Subject: [PATCH 3/3] vhost_xen: Implement Xen foreign mappings along with
 grant mappings

As a prereq for foreign mapping scheme, refactor the module heavily
to be able to reuse common stuff between mapping schemes and perform
some renamings accordingly. Also reduce the mapping context which
needs to be stored in struct vhost_xen_map. Move mapping specific
details into struct vhost_xen_ops. Introduce "nogrant" param to be
able to choose the target mappings.

The proper solution would be to pass the grant_usage from Qemu directly
by extending some of VHOST ioctls (for example, VHOST_SET_MEM_TABLE).

Signed-off-by: Oleksandr Tyshchenko <oleksandr_tyshchenko@epam.com>
---
 drivers/vhost/Kconfig |   2 +-
 drivers/vhost/vhost.h |   2 +-
 drivers/vhost/xen.c   | 282 ++++++++++++++++++++++++++++++++----------
 3 files changed, 216 insertions(+), 70 deletions(-)

diff --git a/drivers/vhost/Kconfig b/drivers/vhost/Kconfig
index 3c85221120e5..39a144cee001 100644
--- a/drivers/vhost/Kconfig
+++ b/drivers/vhost/Kconfig
@@ -9,7 +9,7 @@ config VHOST_IOTLB
 config VHOST_XEN
 	tristate
 	help
-	  Support of Xen grant mappings for accessing descriptors in virtio rings.
+	  Support of Xen specific mappings for accessing descriptors in virtio rings.
 
 config VHOST_RING
 	tristate
diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h
index 822e7e200a9a..8396e54ce1ce 100644
--- a/drivers/vhost/vhost.h
+++ b/drivers/vhost/vhost.h
@@ -135,7 +135,7 @@ struct vhost_virtqueue {
 
 #ifdef CONFIG_VHOST_XEN
 	/*
-	 * Contains virtio descriptors mapped by using Xen grant mappings
+	 * Contains virtio descriptors mapped by using Xen specific mappings
 	 * in order to handle current request. To be unmapped once the request
 	 * is processed.
 	 */
diff --git a/drivers/vhost/xen.c b/drivers/vhost/xen.c
index d4466a1c3c2c..bdeca47a3121 100644
--- a/drivers/vhost/xen.c
+++ b/drivers/vhost/xen.c
@@ -1,9 +1,11 @@
 // SPDX-License-Identifier: GPL-2.0-only
 /*
  * A specific module for accessing descriptors in virtio rings which contain
- * guest grant based addresses instead of pseudo-physical addresses.
+ * either usual guest pseudo-physical addresses or guest grant based addresses.
+ * Depending on the descriptor's nature we use either Xen foreign mappings or
+ * Xen grant mappings to map/unmap an underlying guest page.
  * Please see Xen grant DMA-mapping layer at drivers/xen/grant-dma-ops.c
- * which is the origin of such mapping scheme.
+ * which is the origin of Xen grant mappings scheme.
  *
  * Copyright (C) 2023 EPAM Systems Inc.
  */
@@ -14,24 +16,36 @@
 #include <xen/grant_table.h>
 #include <xen/xen.h>
 #include <xen/xenbus.h>
+#include <xen/interface/memory.h>
+#include <asm/xen/hypercall.h>
 
 #include "vhost.h"
 
 static domid_t guest_domid = DOMID_INVALID;
 
-struct vhost_xen_grant_map {
+static bool nogrant;
+module_param(nogrant, bool, 0444);
+MODULE_PARM_DESC(nogrant, "Disable Xen grant mappings");
+
+struct vhost_xen_map {
 	struct list_head next;
 	int count;
-	int flags;
-	grant_ref_t *grefs;
+	grant_handle_t *handles;
 	domid_t domid;
-	struct gnttab_map_grant_ref *map_ops;
-	struct gnttab_unmap_grant_ref *unmap_ops;
 	struct page **pages;
 	unsigned long vaddr;
 };
 
-static void vhost_xen_free_map(struct vhost_xen_grant_map *map)
+struct vhost_xen_ops {
+	struct vhost_xen_map *(*alloc_map)(int count);
+	void (*free_map)(struct vhost_xen_map *map);
+	int (*map_pages)(struct vhost_xen_map *map, u64 gpaddr, bool readonly);
+	int (*unmap_pages)(struct vhost_xen_map *map);
+};
+
+static const struct vhost_xen_ops *vhost_xen_ops;
+
+static void vhost_xen_grant_free_map(struct vhost_xen_map *map)
 {
 	if (!map)
 		return;
@@ -40,93 +54,213 @@ static void vhost_xen_free_map(struct vhost_xen_grant_map *map)
 		gnttab_free_pages(map->count, map->pages);
 
 	kvfree(map->pages);
-	kvfree(map->grefs);
-	kvfree(map->map_ops);
-	kvfree(map->unmap_ops);
+	kvfree(map->handles);
 	kfree(map);
 }
 
-static struct vhost_xen_grant_map *vhost_xen_alloc_map(int count)
+static struct vhost_xen_map *vhost_xen_grant_alloc_map(int count)
 {
-	struct vhost_xen_grant_map *map;
-	int i;
+	struct vhost_xen_map *map;
 
 	map = kzalloc(sizeof(*map), GFP_KERNEL);
 	if (!map)
 		return NULL;
 
-	map->grefs = kvcalloc(count, sizeof(map->grefs[0]), GFP_KERNEL);
-	map->map_ops = kvcalloc(count, sizeof(map->map_ops[0]), GFP_KERNEL);
-	map->unmap_ops = kvcalloc(count, sizeof(map->unmap_ops[0]), GFP_KERNEL);
+	map->handles = kvcalloc(count, sizeof(map->handles[0]), GFP_KERNEL);
 	map->pages = kvcalloc(count, sizeof(map->pages[0]), GFP_KERNEL);
-	if (!map->grefs || !map->map_ops || !map->unmap_ops || !map->pages)
+	if (!map->handles || !map->pages)
 		goto err;
 
 	if (gnttab_alloc_pages(count, map->pages))
 		goto err;
 
-	for (i = 0; i < count; i++) {
-		map->map_ops[i].handle = -1;
-		map->unmap_ops[i].handle = -1;
-	}
-
 	map->count = count;
 
 	return map;
 
 err:
-	vhost_xen_free_map(map);
+	vhost_xen_grant_free_map(map);
 
 	return NULL;
 }
 
-static int vhost_xen_map_pages(struct vhost_xen_grant_map *map)
+static int vhost_xen_grant_map_pages(struct vhost_xen_map *map, u64 gpaddr,
+		bool readonly)
 {
-	int i, ret = 0;
+	struct gnttab_map_grant_ref *map_ops;
+	int i, ret;
+	uint32_t flags = GNTMAP_host_map;
+
+	map_ops = kvcalloc(map->count, sizeof(map_ops[0]), GFP_KERNEL);
+	if (!map_ops)
+		return -ENOMEM;
 
-	if (map->map_ops[0].handle != -1)
-		return -EINVAL;
+	if (readonly)
+		flags |= GNTMAP_readonly;
 
 	for (i = 0; i < map->count; i++) {
 		unsigned long vaddr = (unsigned long)
 			pfn_to_kaddr(page_to_xen_pfn(map->pages[i]));
-		gnttab_set_map_op(&map->map_ops[i], vaddr, map->flags,
-			map->grefs[i], map->domid);
-		gnttab_set_unmap_op(&map->unmap_ops[i], vaddr, map->flags, -1);
+		grant_ref_t ref = XEN_PFN_DOWN(gpaddr & ~XEN_GRANT_DMA_ADDR_OFF) + i;
+
+		gnttab_set_map_op(&map_ops[i], vaddr, flags, ref, map->domid);
+		map->handles[i] = -1;
 	}
 
-	ret = gnttab_map_refs(map->map_ops, NULL, map->pages, map->count);
+	ret = gnttab_map_refs(map_ops, NULL, map->pages, map->count);
 	for (i = 0; i < map->count; i++) {
-		if (map->map_ops[i].status == GNTST_okay)
-			map->unmap_ops[i].handle = map->map_ops[i].handle;
+		if (map_ops[i].status == GNTST_okay)
+			map->handles[i] = map_ops[i].handle;
 		else if (!ret)
 			ret = -EINVAL;
 	}
 
+	kvfree(map_ops);
+
 	return ret;
 }
 
-static int vhost_xen_unmap_pages(struct vhost_xen_grant_map *map)
+static int vhost_xen_grant_unmap_pages(struct vhost_xen_map *map)
 {
+	struct gnttab_unmap_grant_ref *unmap_ops;
 	int i, ret;
 
-	if (map->unmap_ops[0].handle == -1)
-		return -EINVAL;
+	unmap_ops = kvcalloc(map->count, sizeof(unmap_ops[0]), GFP_KERNEL);
+	if (!unmap_ops)
+		return -ENOMEM;
 
-	ret = gnttab_unmap_refs(map->unmap_ops, NULL, map->pages, map->count);
-	if (ret)
+	for (i = 0; i < map->count; i++) {
+		unsigned long vaddr = (unsigned long)
+			pfn_to_kaddr(page_to_xen_pfn(map->pages[i]));
+
+		gnttab_set_unmap_op(&unmap_ops[i], vaddr, GNTMAP_host_map,
+				map->handles[i]);
+	}
+
+	ret = gnttab_unmap_refs(unmap_ops, NULL, map->pages, map->count);
+	if (ret) {
+		kvfree(unmap_ops);
 		return ret;
+	}
 
 	for (i = 0; i < map->count; i++) {
-		if (map->unmap_ops[i].status != GNTST_okay)
+		if (unmap_ops[i].status != GNTST_okay)
 			ret = -EINVAL;
-		map->unmap_ops[i].handle = -1;
+		map->handles[i] = -1;
+	}
+
+	kvfree(unmap_ops);
+
+	return ret;
+}
+
+static void vhost_xen_foreign_free_map(struct vhost_xen_map *map)
+{
+	if (!map)
+		return;
+
+	if (map->pages)
+		xen_free_unpopulated_pages(map->count, map->pages);
+
+	kvfree(map->pages);
+	kfree(map);
+}
+
+static struct vhost_xen_map *vhost_xen_foreign_alloc_map(int count)
+{
+	struct vhost_xen_map *map;
+
+	map = kzalloc(sizeof(*map), GFP_KERNEL);
+	if (!map)
+		return NULL;
+
+	map->pages = kvcalloc(count, sizeof(map->pages[0]), GFP_KERNEL);
+	if (!map->pages)
+		goto err;
+
+	if (xen_alloc_unpopulated_pages(count, map->pages))
+		goto err;
+
+	map->count = count;
+
+	return map;
+
+err:
+	vhost_xen_foreign_free_map(map);
+
+	return NULL;
+}
+
+static int vhost_xen_foreign_map_pages(struct vhost_xen_map *map, u64 gpaddr,
+		bool readonly)
+{
+	xen_pfn_t *gpfns;
+	xen_ulong_t *idxs;
+	int *errs;
+	int i, ret;
+
+	struct xen_add_to_physmap_range xatp = {
+		.domid = DOMID_SELF,
+		.foreign_domid = map->domid,
+		.space = XENMAPSPACE_gmfn_foreign,
+	};
+
+	gpfns = kvcalloc(map->count, sizeof(xen_pfn_t), GFP_KERNEL);
+	idxs = kvcalloc(map->count, sizeof(xen_ulong_t), GFP_KERNEL);
+	errs = kvcalloc(map->count, sizeof(int), GFP_KERNEL);
+	if (!gpfns || !idxs || !errs) {
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < map->count; i++) {
+		xen_pfn_t pfn = page_to_xen_pfn(map->pages[i / XEN_PFN_PER_PAGE]);
+		xen_ulong_t idx = XEN_PFN_DOWN(gpaddr) + i;
+
+		gpfns[i] = pfn + (i % XEN_PFN_PER_PAGE);
+		idxs[i] = idx;
+		errs[i] = 0;
+	}
+
+	xatp.size = map->count;
+	set_xen_guest_handle(xatp.gpfns, gpfns);
+	set_xen_guest_handle(xatp.idxs, idxs);
+	set_xen_guest_handle(xatp.errs, errs);
+
+	ret = HYPERVISOR_memory_op(XENMEM_add_to_physmap_range, &xatp);
+	for (i = 0; i < map->count; i++) {
+		if (errs[i] && !ret)
+			ret = errs[i];
 	}
 
+out:
+	kvfree(gpfns);
+	kvfree(idxs);
+	kvfree(errs);
+
 	return ret;
 }
 
-static void vhost_xen_put_map(struct vhost_xen_grant_map *map)
+static int vhost_xen_foreign_unmap_pages(struct vhost_xen_map *map)
+{
+	int i, ret = 0;
+	struct xen_remove_from_physmap xrp;
+
+	for (i = 0; i < map->count; i++) {
+		xen_pfn_t pfn = page_to_xen_pfn(map->pages[i / XEN_PFN_PER_PAGE]);
+
+		xrp.domid = DOMID_SELF;
+		xrp.gpfn = pfn + (i % XEN_PFN_PER_PAGE);
+
+		ret = HYPERVISOR_memory_op(XENMEM_remove_from_physmap, &xrp);
+		if (ret)
+			return ret;
+	}
+
+	return ret;
+}
+
+static void vhost_xen_put_map(struct vhost_xen_map *map)
 {
 	if (!map)
 		return;
@@ -140,18 +274,18 @@ static void vhost_xen_put_map(struct vhost_xen_grant_map *map)
 	if (map->pages) {
 		int ret;
 
-		ret = vhost_xen_unmap_pages(map);
+		ret = vhost_xen_ops->unmap_pages(map);
 		if (ret)
 			pr_err("%s: Failed to unmap pages from dom%d (ret=%d)\n",
 					__func__, map->domid, ret);
 	}
-	vhost_xen_free_map(map);
+	vhost_xen_ops->free_map(map);
 }
 
-static struct vhost_xen_grant_map *vhost_xen_find_map(struct vhost_virtqueue *vq,
+static struct vhost_xen_map *vhost_xen_find_map(struct vhost_virtqueue *vq,
 		unsigned long vaddr, int count)
 {
-	struct vhost_xen_grant_map *map;
+	struct vhost_xen_map *map;
 
 	list_for_each_entry(map, &vq->desc_maps, next) {
 		if (map->vaddr != vaddr)
@@ -166,13 +300,13 @@ static struct vhost_xen_grant_map *vhost_xen_find_map(struct vhost_virtqueue *vq
 
 void vhost_xen_unmap_desc_all(struct vhost_virtqueue *vq)
 {
-	struct vhost_xen_grant_map *map;
+	struct vhost_xen_map *map;
 
 	if (!xen_domain())
 		return;
 
 	while (!list_empty(&vq->desc_maps)) {
-		map = list_entry(vq->desc_maps.next, struct vhost_xen_grant_map, next);
+		map = list_entry(vq->desc_maps.next, struct vhost_xen_map, next);
 		list_del(&map->next);
 
 		pr_debug("%s: dom%d: vaddr 0x%lx count %u\n",
@@ -181,39 +315,34 @@ void vhost_xen_unmap_desc_all(struct vhost_virtqueue *vq)
 	}
 }
 
-void *vhost_xen_map_desc(struct vhost_virtqueue *vq, u64 addr, u32 size, int access)
+void *vhost_xen_map_desc(struct vhost_virtqueue *vq, u64 addr, u32 size,
+		int access)
 {
-	struct vhost_xen_grant_map *map;
+	struct vhost_xen_map *map;
 	unsigned long offset = xen_offset_in_page(addr);
 	int count = XEN_PFN_UP(offset + size);
-	int i, ret;
+	int ret;
 
 	if (!xen_domain() || guest_domid == DOMID_INVALID)
 		return ERR_PTR(-ENODEV);
 
-	if (!(addr & XEN_GRANT_DMA_ADDR_OFF)) {
-		pr_err("%s: Descriptor from dom%d cannot be mapped (0x%llx is not a Xen grant address)\n",
-				__func__, guest_domid, addr);
+	if ((nogrant && (addr & XEN_GRANT_DMA_ADDR_OFF)) ||
+			(!nogrant && !(addr & XEN_GRANT_DMA_ADDR_OFF))) {
+		pr_err("%s: Descriptor from dom%d cannot be mapped via Xen %s mappings (addr 0x%llx)\n",
+				__func__, guest_domid, nogrant ? "foreign" : "grant", addr);
 		return ERR_PTR(-EINVAL);
 	}
 
-	map = vhost_xen_alloc_map(count);
+	map = vhost_xen_ops->alloc_map(count);
 	if (!map)
 		return ERR_PTR(-ENOMEM);
 
 	map->domid = guest_domid;
-	for (i = 0; i < count; i++)
-		map->grefs[i] = ((addr & ~XEN_GRANT_DMA_ADDR_OFF) >> XEN_PAGE_SHIFT) + i;
-
-	map->flags |= GNTMAP_host_map;
-	if (access == VHOST_ACCESS_RO)
-		map->flags |= GNTMAP_readonly;
-
-	ret = vhost_xen_map_pages(map);
+	ret = vhost_xen_ops->map_pages(map, addr, access == VHOST_ACCESS_RO);
 	if (ret) {
 		pr_err("%s: Failed to map pages from dom%d (ret=%d)\n",
 				__func__, map->domid, ret);
-		vhost_xen_put_map(map);
+		vhost_xen_ops->free_map(map);
 		return ERR_PTR(ret);
 	}
 
@@ -236,7 +365,7 @@ void *vhost_xen_map_desc(struct vhost_virtqueue *vq, u64 addr, u32 size, int acc
 	list_add_tail(&map->next, &vq->desc_maps);
 
 	pr_debug("%s: dom%d: addr 0x%llx size 0x%x (access 0x%x) -> vaddr 0x%lx count %u (paddr 0x%llx)\n",
-			__func__, map->domid, addr, size, access, map->vaddr, count,
+			__func__, map->domid, addr, size, access, map->vaddr, map->count,
 			page_to_phys(map->pages[0]));
 
 	return (void *)(map->vaddr + offset);
@@ -244,7 +373,7 @@ void *vhost_xen_map_desc(struct vhost_virtqueue *vq, u64 addr, u32 size, int acc
 
 void vhost_xen_unmap_desc(struct vhost_virtqueue *vq, void *ptr, u32 size)
 {
-	struct vhost_xen_grant_map *map;
+	struct vhost_xen_map *map;
 	unsigned long offset = xen_offset_in_page(ptr);
 	int count = XEN_PFN_UP(offset + size);
 
@@ -261,6 +390,20 @@ void vhost_xen_unmap_desc(struct vhost_virtqueue *vq, void *ptr, u32 size)
 	}
 }
 
+static const struct vhost_xen_ops vhost_xen_grant_ops = {
+	.alloc_map = vhost_xen_grant_alloc_map,
+	.free_map = vhost_xen_grant_free_map,
+	.map_pages = vhost_xen_grant_map_pages,
+	.unmap_pages = vhost_xen_grant_unmap_pages,
+};
+
+static const struct vhost_xen_ops vhost_xen_foreign_ops = {
+	.alloc_map = vhost_xen_foreign_alloc_map,
+	.free_map = vhost_xen_foreign_free_map,
+	.map_pages = vhost_xen_foreign_map_pages,
+	.unmap_pages = vhost_xen_foreign_unmap_pages,
+};
+
 static void vhost_xen_get_guest_domid(struct xenbus_watch *watch,
 		const char *path, const char *token)
 {
@@ -308,7 +451,10 @@ static int __init vhost_xen_init(void)
 
 	register_xenstore_notifier(&vhost_xen_notifier);
 
-	pr_info("%s: Initialize module for Xen grant mappings\n", __func__);
+	vhost_xen_ops = nogrant ? &vhost_xen_foreign_ops : &vhost_xen_grant_ops;
+
+	pr_info("%s: Initialize module for Xen %s mappings\n", __func__,
+			nogrant ? "foreign" : "grant");
 
 	return 0;
 }
@@ -321,6 +467,6 @@ static void __exit vhost_xen_exit(void)
 module_init(vhost_xen_init);
 module_exit(vhost_xen_exit);
 
-MODULE_DESCRIPTION("Xen grant mappings module for vhost");
+MODULE_DESCRIPTION("Xen specific mappings for vhost");
 MODULE_AUTHOR("Oleksandr Tyshchenko <oleksandr_tyshchenko@epam.com>");
 MODULE_LICENSE("GPL v2");
-- 
2.34.1

